{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangchainのGraphRAGの記事  \n",
    "https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import (\n",
    "    AzureOpenAIEmbeddings,\n",
    "    OpenAIEmbeddings,\n",
    "    AzureChatOpenAI,\n",
    "    ChatOpenAI\n",
    ")\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Model読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emmbeddingsのモデルを取得\n",
    "embeddings = None\n",
    "if os.getenv('AZURE_OPENAI_API_KEY') != \"\":\n",
    "    # Azureの場合\n",
    "    embeddings = AzureOpenAIEmbeddings(\n",
    "        azure_deployment=\"embedding\",\n",
    "        openai_api_version=\"2024-06-01\"\n",
    "    )\n",
    "elif os.getenv('OPENAI_API_KEY') != \"\":\n",
    "    # OpenAIの場合\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "else:\n",
    "    print(\"APIKeyの設定を確認してください\")\n",
    "\n",
    "# chatのモデルを取得\n",
    "model = None\n",
    "if os.getenv('AZURE_OPENAI_API_KEY') != \"\":\n",
    "    # Azureの場合\n",
    "    model = AzureChatOpenAI(\n",
    "        azure_deployment=\"chat\",\n",
    "        openai_api_version=\"2024-06-01\",\n",
    "        temperature=0.\n",
    "    )\n",
    "elif os.getenv('OPENAI_API_KEY') != \"\":\n",
    "    # OpenAIの場合\n",
    "    model = ChatOpenAI(model=\"gpt-4\")\n",
    "else:\n",
    "    print(\"APIKeyの設定を確認してください\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. データの準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-1. データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/工事マスター.csv', encoding=\"cp932\")\n",
    "df[[\"工事名\", \"備考\"]].to_csv('data/temp.csv', encoding=\"cp932\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "loader = CSVLoader(\n",
    "    file_path=\"./data/temp.csv\",\n",
    "    encoding=\"cp932\",\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-2. Graph作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_transformer = LLMGraphTransformer(llm=model)\n",
    "# Extract graph data\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"graph_documents len\",len(graph_documents)) \n",
    "print(\"graph_documents\", graph_documents[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a graph\n",
    "graph = Neo4jGraph()\n",
    "\n",
    "# 実行するとデータの削除可能\n",
    "# graph.query(\"MATCH (n) DETACH DELETE n\")\n",
    "\n",
    "# Store graph data\n",
    "graph.add_graph_documents(\n",
    "  graph_documents, \n",
    "  baseEntityLabel=True, \n",
    "  include_source=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Unstructured data retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Neo4jVector\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    embeddings,\n",
    "    search_type=\"hybrid\", # ハイブリッド検索: キーワード検索インデックスとベクトル検索インデックスを構成\n",
    "    node_label=\"Document\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index.similarity_search(\"学校が建設される市はどこですか？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Graph retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-1. pydanticの補足\n",
    "グラフ検索用のエンティティを取得する際に、LLMで出力した内容で、Pythonオブジェクトに変換しています。  \n",
    "ここで簡単に、Pythonのオブジェクトに変換について見ていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Tuple, List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car(BaseModel):\n",
    "    name: str = Field(..., title=\"車名\")\n",
    "    color: str = Field(..., title=\"色\")\n",
    "    price: int = Field(..., title=\"価格\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"テキストから車の名称、色、価格を抽出します。\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"指定された形式を使用して、以下から情報を抽出します。\"\n",
    "            \"input: {question}\",\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 何もしない場合\n",
    "chain = prompt|model\n",
    "chain.invoke(\"TOYOTAの人気の車は黒のカローラシリーズで、価格は300万円ほどです\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pythonオブジェクトに変換する場合\n",
    "chain = prompt|model.with_structured_output(Car)\n",
    "car = chain.invoke(\"TOYOTAの人気の車は黒のカローラシリーズで、価格は300万円ほどです\")\n",
    "print(car)\n",
    "print(car.name, car.color, car.price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-2. エンティティの取得\n",
    " グラフ検索に使うエンティティを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract entities from text\n",
    "class Entities(BaseModel):\n",
    "    \"\"\"エンティティに関する情報の識別\"\"\"\n",
    "\n",
    "    names: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"文章の中に登場する、工事の場所、工事の名前、工事の種類などのエンティティのリスト\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"テキストから工事の場所、工事の種類、建物の種類のエンティティを抽出します。\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"指定された形式を使用して、以下から情報を抽出します。\"\n",
    "            \"input: {question}\",\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pythonオブジェクト変換する場合\n",
    "entity_chain = prompt | model.with_structured_output(Entities)\n",
    "entity_chain.invoke({\"question\": \"学校が建設される市はどこですか？\"}).names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-3. graph retriever　実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
    "\n",
    "# 全文検索インデックスを作成\n",
    "graph.query(\"CREATE FULLTEXT INDEX entity IF NOT EXISTS FOR (e:__Entity__) ON EACH [e.id]\")\n",
    "\n",
    "# スペルミスを許容する全文検索クエリを生成\n",
    "def generate_full_text_query(input: str) -> str:\n",
    "    \"\"\"\n",
    "    次の文字列入力に対して「全文検索」クエリを生成します。\n",
    "\n",
    "    この関数は全文検索に適したクエリ文字列を構築します。\n",
    "    入力文字列を単語に分割し、各単語に類似性の閾値（最大2文字の変更）を付けて、AND演算子を用いてそれらを結合します。\n",
    "    ユーザーの質問からデータベースの値にエンティティをマッピングするのに役立ち、多少のスペルミスを許容します。\n",
    "    \"\"\"\n",
    "    full_text_query = \"\"\n",
    "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
    "    for word in words[:-1]:\n",
    "        full_text_query += f\" {word}~2 AND\"\n",
    "    full_text_query += f\" {words[-1]}~2\"\n",
    "    return full_text_query.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " 各単語に「2」を付け加えます。これは、Luceneクエリ構文で、最大2文字の変更を許容することを意味します。\n",
    " 例えば、「apple2」というクエリは「apple」、「aple」、「appla」など、2文字までの違いがある単語もマッチします\n",
    "\"\"\"\n",
    "generate_full_text_query(\"病院\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fulltext index query\n",
    "def structured_retriever(question: str) -> str:\n",
    "    \"\"\"\n",
    "    質問に記載されているエンティティの近傍を収集します。\n",
    "    \"\"\"\n",
    "    result = \"\"\n",
    "    # エンティティを抽出します\n",
    "    entities = entity_chain.invoke({\"question\": question})\n",
    "    # クエリを実行し、エンティティの近傍を収集します\n",
    "    for entity in entities.names:\n",
    "        response = graph.query(\n",
    "            \"\"\"CALL db.index.fulltext.queryNodes('entity', $query, \n",
    "            {limit:2})\n",
    "            YIELD node,score\n",
    "            CALL {\n",
    "              MATCH (node)-[r:!MENTIONS]->(neighbor)\n",
    "              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS \n",
    "              output\n",
    "              UNION\n",
    "              MATCH (node)<-[r:!MENTIONS]-(neighbor)\n",
    "              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS \n",
    "              output\n",
    "            }\n",
    "            RETURN output LIMIT 50\n",
    "            \"\"\",\n",
    "            {\"query\": generate_full_text_query(entity)},\n",
    "        )\n",
    "        result += \"\\n\".join([el['output'] for el in response])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(structured_retriever(\"学校が建設される市はどこですか？\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Structured(Graph)とUnStructured(Vector)を合わせたレトリーバー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retriever(question: str):\n",
    "    print(f\"Search query: {question}\")\n",
    "    structured_data = structured_retriever(question)\n",
    "    unstructured_data = [el.page_content for el in vector_index.similarity_search(question, k=10)]\n",
    "    final_data = f\"\"\"Structured data:\n",
    "{structured_data}\n",
    "Unstructured data:\n",
    "\n",
    "{\"#Document \". join(unstructured_data)}\n",
    "    \"\"\"\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever(\"学校が建設される市はどこですか？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. RAGチェーンの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import (RunnableBranch, RunnableLambda, RunnableParallel,RunnablePassthrough)\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-1. retrieverの実行\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終的なretrieverの結果\n",
    "context = retriever(\"学校が建設される市はどこですか？\")\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベクトル検索のretrieverの結果\n",
    "unstructured_data = [el.page_content for el in vector_index.similarity_search(\"学校が建設される市はどこですか？\", k=10)]\n",
    "unstructured_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-2. 回答を得る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "以下のコンテキストに基づいて質問に答えてください。 \n",
    "{context} \n",
    "質問: {question}\n",
    " \"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "chain = (\n",
    "    prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphとベクトル検索を組み合わせて、質問に答える\n",
    "chain.invoke({\n",
    "    \"context\": context, \n",
    "    \"question\": \"学校が建設される市はどこですか？\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベクトル検索のみを使用して、質問に答える\n",
    "chain.invoke({\n",
    "    \"context\": unstructured_data, \n",
    "    \"question\": \"学校が建設される市はどこですか？\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-3. 1つのChainに実装\n",
    "チャット履歴の対応\n",
    "\n",
    "目指すコード\n",
    "```python\n",
    "chain = (\n",
    "    RunnableParallel(\n",
    "        {\n",
    "            \"context\": _search_query | retriever,\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "    )\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "# チャット履歴とその後の質問を要約して、独立した質問に変換する\n",
    "_template = \"\"\"\n",
    "次の「チャット履歴」とそれに「続く質問」をもとに、独立した質問に言い換えてください。\n",
    "独立した質問は履歴情報が含まれた質問としてください。\n",
    "チャット履歴:\n",
    "{chat_history}\n",
    "続く質問: {question}\n",
    "\"\"\"\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)\n",
    "\n",
    "def _format_chat_history(chat_history: List[Tuple[str, str]]) -> List:\n",
    "    buffer = []\n",
    "    for human, ai in chat_history:\n",
    "        buffer.append(HumanMessage(content=human))\n",
    "        buffer.append(AIMessage(content=ai))\n",
    "    return buffer\n",
    "\n",
    "_search_query = RunnableBranch(\n",
    "    # 入力にチャット履歴が含まれている場合、それをその後の質問とともに要約します\n",
    "    (\n",
    "        RunnableLambda(lambda x: bool(x.get(\"chat_history\"))).with_config(\n",
    "            run_name=\"HasChatHistoryCheck\"\n",
    "        ),  # Condense follow-up question and chat into a standalone_question\n",
    "        RunnablePassthrough.assign(\n",
    "            chat_history=lambda x: _format_chat_history(x[\"chat_history\"])\n",
    "        )\n",
    "        | CONDENSE_QUESTION_PROMPT\n",
    "        | model\n",
    "        | StrOutputParser(),\n",
    "    ),\n",
    "    # それ以外の場合は、チャット履歴がないため、質問のみを通過させます\n",
    "    RunnableLambda(lambda x : x[\"question\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_search_queryの動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_search_query.invoke({\"question\": \"学校が建設される市はどこですか？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_search_query.invoke(\n",
    "    {\n",
    "        \"question\": \"高崎市で行われる工事の概要を教えてください\",\n",
    "        \"chat_history\": [\n",
    "            (\n",
    "                \"学校が建設される市はどこですか？\",\n",
    "                \"学校が建設される市は以下の通りです：\\n\\n1. 高崎市\\n2. 伊勢崎市\\n3. 太田市\\n4. 藤岡市\\n5. 館林市\\n6. 安中市\\n\\nこれらの市で学校の建設プロジェクトが行われています。\"\n",
    "            )\n",
    "        ],\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RunnableParallelで実行する処理の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_chain = RunnableParallel(\n",
    "        {\n",
    "            \"context\": _search_query | retriever,\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 質問だけの場合\n",
    "parallel_chain.invoke({\"question\": \"学校が建設される市はどこですか？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 会話履歴もある場合\n",
    "parallel_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"高崎市で行われる工事の概要を教えてください\",\n",
    "        \"chat_history\": [\n",
    "            (\n",
    "                \"学校が建設される市はどこですか？\",\n",
    "                \"学校が建設される市は以下の通りです：\\n\\n1. 高崎市\\n2. 伊勢崎市\\n3. 太田市\\n4. 藤岡市\\n5. 館林市\\n6. 安中市\\n\\nこれらの市で学校の建設プロジェクトが行われています。\"\n",
    "            )\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    RunnableParallel(\n",
    "        {\n",
    "            \"context\": _search_query | retriever,\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "    )\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"question\": \"学校が建設される市はどこですか？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "        \"question\": \"高崎市で行われる工事の概要を教えてください\",\n",
    "        \"chat_history\": [\n",
    "            (\n",
    "                \"学校が建設される市はどこですか？\",\n",
    "                \"学校が建設される市は以下の通りです：\\n1. 高崎市\\n2. 伊勢崎市\\n3. 太田市\\n4. 藤岡市\\n5. 館林市\\n6. 安中市\\n\\nこれらの市で学校の建設プロジェクトが行われています。\"\n",
    "            )\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
