{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAGを使ってチャット\n",
    "1. Model読み込み\n",
    "2. PromptTemplateの設定\n",
    "3. FAISSのvector dataを取得\n",
    "4. Chatの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import (\n",
    "    AzureOpenAIEmbeddings,\n",
    "    OpenAIEmbeddings,\n",
    "    AzureChatOpenAI,\n",
    "    ChatOpenAI\n",
    ")\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    HumanMessage, \n",
    "    AIMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Model読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emmbeddingsのモデルを取得\n",
    "embeddings = None\n",
    "if os.getenv('AZURE_OPENAI_API_KEY') != \"\":\n",
    "    # Azureの場合\n",
    "    embeddings = AzureOpenAIEmbeddings(\n",
    "        azure_deployment=\"embedding\",\n",
    "        openai_api_version=\"2024-06-01\"\n",
    "    )\n",
    "elif os.getenv('OPENAI_API_KEY') != \"\":\n",
    "    # OpenAIの場合\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "else:\n",
    "    print(\"APIKeyの設定を確認してください\")\n",
    "\n",
    "# chatのモデルを取得\n",
    "model = None\n",
    "if os.getenv('AZURE_OPENAI_API_KEY') != \"\":\n",
    "    # Azureの場合\n",
    "    model = AzureChatOpenAI(\n",
    "        azure_deployment=\"chat\",\n",
    "        openai_api_version=\"2024-06-01\"\n",
    "    )\n",
    "elif os.getenv('OPENAI_API_KEY') != \"\":\n",
    "    # OpenAIの場合\n",
    "    model = ChatOpenAI(model=\"gpt-4\")\n",
    "else:\n",
    "    print(\"APIKeyの設定を確認してください\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.PromptTemplateの設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-1. コンテキストから回答するプロンプトとChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"あなたは質問対応のアシスタントです。\"\n",
    "    \"質問に答えるために、検索された文脈の以下の部分を使用してください。\"\n",
    "    \"答えがわからない場合は、わからないと答えてください。\"\n",
    "    \"回答は3文以内で簡潔にしてください。\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-2. 質問を要約するプロンプトとChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "contextualize_q_system_prompt = (\n",
    "    \"あなたは、AIでチャットの質問を作り直すように求められています。\"\n",
    "    \"チャット履歴と最新のユーザーメッセージがあり、そのメッセージは\"\n",
    "    \"チャット履歴のコンテキストを参照している質問である可能性があります。\"\n",
    "    \"チャット履歴がなくても、理解できる独立した質問を作成してください。\"\n",
    "    \"絶対に、質問に答えないでください。\"\n",
    "    \"質問は、「教えてください。」「どういうことですか？」などAIに投げかける質問にしてください。\"\n",
    "    \"メッセージが質問であれば、作り直してください。\"\n",
    "    \"「ありがとう」などメッセージが質問ではない場合は、メッセージを作り直さず戻してください。\"\n",
    "    \"\\n\\n\"\n",
    ")\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "contextualize_chain = contextualize_q_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. FAISSのvector dataを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.load_local(\"./db\", embeddings, allow_dangerous_deserialization=True)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Chatの実装\n",
    "チャットの実装では下記図のように2段階の処理をしていきます  \n",
    "<img src=\"./../docs/asset/image3.png\" width=\"600px\">  \n",
    "\n",
    "<a href=\"https://python.langchain.com/v0.2/docs/tutorials/qa_chat_history/\" target=_blank>Langchain Doc</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-1. 二つの質問をしてみる\n",
    " まず、1つ目のステップを確認していきます。  \n",
    " なぜ1つ目の処理をする必要があるのかをみるために、2つの質問をします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LLMの訓練方法には、教師あり学習、強化学習（RLHF）、そしてファインチューニングが含まれます。例えば、OpenAIのInstructGPTプロトコルは、人間が作成したプロンプトと応答の組からなるデータセットを用いた教師ありファインチューニングと、その後の人間のフィードバックを用いた強化学習を行います。', response_metadata={'token_usage': {'completion_tokens': 138, 'prompt_tokens': 4038, 'total_tokens': 4176}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_e49e4201a9', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-0b89b3f3-2a43-4fc0-b014-1ec8907088f1-0', usage_metadata={'input_tokens': 4038, 'output_tokens': 138, 'total_tokens': 4176})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = []\n",
    "msg1 = \"LLMはどんな訓練方法がありますか？\"\n",
    "relavant_docs = retriever.invoke(msg1, k=3)\n",
    "chain.invoke({\"chat_history\": messages, \"context\": relavant_docs, \"input\": msg1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='申し訳ありませんが、具体的な教師ありファインチューニングについての説明は提供されていません。このトピックについては、追加情報が必要です。', response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 4347, 'total_tokens': 4413}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_e49e4201a9', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-09a8c5e8-3d09-4c6a-9c80-33118c575435-0', usage_metadata={'input_tokens': 4347, 'output_tokens': 66, 'total_tokens': 4413})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(content=\"LLMはどんな訓練方法がありますか？\"),\n",
    "    AIMessage(content=\"LLMの訓練方法には、教師ありファインチューニング、強化学習、ツールのファインチューニング、検索拡張生成（RAG）などがあります。\"),\n",
    "]\n",
    "msg2 = \"1つ目について教えてください。\"\n",
    "relavant_docs = retriever.invoke(msg2, k=3)\n",
    "chain.invoke({\"chat_history\": messages, \"context\": relavant_docs, \"input\": msg2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「\"1つ目について教えてください。\"」からだと正確なドキュメントが取得できない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='ス埋めパズル、ヒングリッシュ（ヒンディー語と英語の混成語）の段落内\n",
      "の不快な内容の特定、およびスワヒリ語のことわざに相当する英語の⽣\n",
      "成などがある[16]。\n",
      "Schaeffer らは、創発的な能⼒は予測不可能な形で獲得されるのではなく、滑らかなスケーリング則に従って\n",
      "予測通りに獲得されると主張している[17]。著者らは、 LLM が多肢選択問題を解く統計的トイモデルを検討\n",
      "し、他の種類のタスクを考慮して修正されたこの統計モデルが、これらのタスクにも適⽤できることを⽰し\n",
      "た。\n",
      "ここで、 をパラメータ数、  をモデルの性能と する。\n",
      "のとき、  は指数曲線 （1でプラトーに達する前）となり、創発\n",
      "のように⾒え る。\n",
      " のとき、  のプロットは直線（0でプラトーに達 する前）\n",
      "となり、創発には⾒えない。創発的能⼒ のとき、  はステッ プ関数 となり、創発の\n",
      "ように⾒え る。\n",
      "⼤規模⾔語モデルの基本的な考え⽅は、単純で反復的なアーキテクチャを持つランダムな重みを持つニュー\n",
      "ラルネットワークを出発点とし、⼤規模な⾔語コー パスで訓練することである。\n",
      "この最も初期の例のひとつがエルマンネットワークで[18]、「⽝が男を追いかける」のような単純な⽂でリカ\n",
      "レントネットワークを訓練した。訓練したネットワークは、各単語をベクトル（内部表現）に変換した。次\n",
      "にこれらのベクトルを接近度によって⽊構造にクラスタリングした。その結果、ツリーはある構造を⽰すこ\n",
      "とがわかった。動詞と名詞はそれぞれ別の⼤きなクラスターに属していた。名詞のクラスター内には、無⽣\n",
      "物（ inanimates ）と⽣物（ animates ）の 2 つの⼩さなクラ スターがある、などである。\n",
      "別の⽅法として、⾃然⾔語理解を記号プログラムによってコンピュータにプログラムする論理 AIがあった。\n",
      "この⽅法は 1990 年代まで主流であった。単純な機構と⼤規模なコーパスによって⾃然⾔語を学習するという\n",
      "着想は 1950 年代に始まったが、商業的に最初に成功したのは、統計的機械翻訳のためのIBMアライメントモ\n",
      "デル（1990年代）であった。\n",
      "初期の「⼤規模」⾔語モデルは、⻑期・短期記憶（LSTM、 1997 年）などのリカレントアーキテクチャを使'\n",
      "-----\n",
      "page_content='返し触れた虚偽を模倣することで不正確な解答をする可能性がある、 817 問からなる質問応答データセット\n",
      "である。たとえば、 LLM は「 Can you teach an old dog new tricks? （年⽼いた⽝に新しい芸を教えられます\n",
      "か？）」という質問に対して、「you can't teach an old dog new trick s（⽼⽝に新しい芸を仕込むことはでき\n",
      "ない）」という英語の語法に触れた結果、⽂字通り真実でないにもかかわらず、「 No 」と答えるかもしれな\n",
      "い[67]。\n",
      "さらに、 AI が多肢選択式テスト（○ × 式テスト）において、必ずしも実際に訪ねられている設問を理解するこ\n",
      "となく表⾯的な問題⽂の統計的相関を利⽤して正解を推測し、「カンニング」する「ショートカット学習」と\n",
      "呼ばれるケー スもある[68]。\n",
      "敵対的評価データセットのもう⼀つの例は、 Swag とその後継の HellaSw ag である。これは、⽂章を完成させ\n",
      "るためにいくつかの選択肢から⼀つを選択しなければならない問題を集めたものである。不正解の選択肢\n",
      "は、⾔語モデルからサンプリングし、⼀連の分類器でフィルタリングすることで作成された。その結果、⼈タスク固有のデータセットとベンチマーク\n",
      "逆説的に構成された評価間にとっては些細な問題でも、デタセットが作成された当時は、最先端の⾔語モデルの精度は思わしくな\n",
      "かった。たとえば、次の ようなもので ある。\n",
      "フィットネスセンターの看板が⾒える。そして、エクササイズボールに座ったり横たわりなが\n",
      "ら、カメラに向かっ て話しかける男性 が⾒える。その男性は、 ...\n",
      "a) ボールの上を⾛ったり降りたりし て、運動の効果を効率的にする⽅法を実演し ている。\n",
      "b) すべての腕と脚を動かし てたくさんの筋⾁をつけている。\n",
      "c) 次にボールを投げ 、グラフ ィックや ⽣け垣の刈り込みの実演を⾒る。\n",
      "d) ボールの上で腹筋運動をしながら話をし ている[69]。\n",
      "BERTは最も可能性の⾼い補完とし て b) を選択したが、正解は d) である[69]。\n",
      "⼤規模⾔語モデルは、それ⾃体が「ブラックボックス」であり、どのようにして⾔語タスクを実⾏できるの'\n",
      "-----\n",
      "page_content='ンレーカップ決勝戦に進出し、ピッツバーグ・ペンギンズに敗れた。」という⽂を含むテキストが追加される\n",
      "可能性がある[63]。そうでない場合、タスクは「（理解する術がなく）説明できないもの（クローズドブッ\n",
      "ク）」とみなされ、モデルは訓練中に獲得した知識を動員する必要がある[64]。⼀般的な質問回答データセッ\n",
      "トの例とし て、 TruthfulQA 、 Web Q uestions 、 TriviaQA 、 SQuAD などがある[64]。\n",
      "評価⽤データセットは、テキスト補完の形式をとることもできる。この場合、モデルは、プロンプトを完成\n",
      "させるために最も可能性の⾼い単語や⽂章を選択する。たとえば、「アリスはボブと友達だった。アリスは\n",
      "彼⼥の友⼈の＿＿＿を訪ねた。 」のような⽳埋め型の設問である[41]。\n",
      "また、さまざまな評価データセットやタスクを組み合わせた複合ベンチマークも開発されている。たとえ\n",
      "ば、 GLUE 、 SuperGLUE 、 MMLU 、 BIG-bench 、 HELM などがある[65][64]。\n",
      "かつては、評価⽤データセットの⼀部を⼿元に残し、残りの部分で教師ありファインチューニングを⾏い、\n",
      "その後に結果を報告するのが⼀般的であった。現在では、事前訓練されたモデルをプロンプティング技術に\n",
      "よって直接評価することが⼀般的になっている。しかし、特定のタスクに対するプロンプトの作成⽅法、特\n",
      "にプロンプトに付加される解決済みタスクの事例数（nショットプロンプトのn値）については研究者によっ\n",
      "て異なる。\n",
      "⼤規模⾔語モデルの改良が急速に進んでいるため、評価ベンチマークの寿命は短く、最先端のモデルが既存\n",
      "のベンチマークを急速に「飽和」させ、⼈間の注釈者の能⼒をも超えてしまう。そのためベンチマークをよ\n",
      "り難易度が⾼いタスクで置き換えたり、強化したりする取り組みが⾏われ ている[66]。\n",
      "中には敵対的に構築されたデータセットもあり、⼈間と⽐べて既存の⾔語モデルの性能が異常に低いと思わ\n",
      "れる特定の問題に重点が置かれている。その⼀例が TruthfulQA データセットで、⾔語モデルが訓練中に繰り\n",
      "返し触れた虚偽を模倣することで不正確な解答をする可能性がある、 817 問からなる質問応答データセット'\n",
      "-----\n",
      "page_content='引き続きファ インチュ ーニングが可能 である[62]。\n",
      "⾔語モデルの性能を表す最も⼀般的な指標は、所与のテキストコーパスにおける⾔語モデルのパープレキシ\n",
      "ティである。パープレキシティは、モデルがデータセットの内容をどれだけうまく予測できるかを⽰す尺度\n",
      "である。モデルがデータセットに割り当てる尤度（ゆうど）が⾼いほど、パープレキシティは低くなる。数\n",
      "学的には、パー プレキシテ ィは、トー クンごとの平均負対数尤度の対数とし て定義される。\n",
      "ここで、  はテキストコー パス内のトークン数 であり、「 context for token （トークン   の⽂脈）」は使⽤す\n",
      "るLLMの種類に依存する。たとえば、 LLM が⾃⼰回帰型の場合、 「 context for token 」はトークン   よりも\n",
      "前に現れたテキ ストの⼀部である。圧縮\n",
      "評価\n",
      "パープレキシティ⾔語モデルは訓練デタに対して過剰適合する可能性があるため、モデルは通常、未知のデタから構成さ\n",
      "れるテストセットに対するパープレキシティによって評価される。このことは、⼤規模な⾔語モデルを評価\n",
      "する際に、特に重要な課題となる[35]。⾔語モデルの訓練は、主にウェブから収集された、より⼤規模なテ\n",
      "キストコーパスが使⽤されるため、モデルの訓練データに特定のテストセットの⼀部が誤って含まれてしま\n",
      "う可能性がますます⾼くなる[41]。\n",
      "また、⾔語モデルがより具体的な下流タスクを実⾏する能⼒を評価するために、多くのテスト⽤データセッ\n",
      "トやベンチマークが開発されている。テストは、⼀般的な知識、常識的な推論、数学的な問題解決など、さ\n",
      "まざまな能⼒を評価するために設計することができる。\n",
      "評価⽤データセットの⼤区分の 1 つに、質問と正解の組で構成される質問応答データセットがある。たとえ\n",
      "ば、『「サンノゼ・シャークスはスタンレーカップで優勝しましたか ? 」、「いいえ」  』のような組である[63]。\n",
      "質問回答タスクでは、モデルのプロンプトに期待される答えを導き出せるテキストが含まれる場合、「明⽩な\n",
      "もの（オープンブック (en:英語版) ）」とみなされる。たとえば、先の質問には、「 2016 年、シャークスはスタ\n",
      "ンレーカップ決勝戦に進出し、ピッツバーグ・ペンギンズに敗れた。」という⽂を含むテキストが追加される'\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# 類似文書を表示\n",
    "for doc in relavant_docs:\n",
    "    print(doc)\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-2. 履歴から質問を作り直す\n",
    "それを解決するための方法が、1つ目のステップになります。  \n",
    "やっていることは、履歴から質問を作り出しています"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "教師ありファインチューニングについて詳しく説明してください。\n"
     ]
    }
   ],
   "source": [
    "# sample1\n",
    "messages = [\n",
    "    HumanMessage(content=\"LLMはどんな訓練方法がありますか？\"),\n",
    "    AIMessage(content=\"LLMの訓練方法には、教師ありファインチューニング、強化学習、ツールのファインチューニング、検索拡張生成（RAG）などがあります。\"),\n",
    "]\n",
    "new_msg = contextualize_chain.invoke({\"chat_history\": messages, \"input\": \"1つ目についておしえてください\"})\n",
    "print(new_msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pythonの勉強方法として、書籍を使用する方法について詳しく教えてください。\n"
     ]
    }
   ],
   "source": [
    "# sample2\n",
    "messages = [\n",
    "    HumanMessage(content=\"Pythonについて教えて\"),\n",
    "    AIMessage(content=\"Pythonは、1991年にオランダ人プログラマーのグイド・ヴァンロッサム氏によって開発されたオープンソース形式のプログラミング言語です。主に人工知能の開発、データ処理、Webアプリケーションの開発など幅広い用途で使用されています。また、初心者にも学びやすい言語とされ、豊富なライブラリが存在するのが特徴です。\"),\n",
    "    HumanMessage(content=\"どんな勉強方法がありますか？\"),\n",
    "    AIMessage(content=\"Pythonを学ぶ方法にはいくつかの選択肢があります。一つは書籍を使用して学習する方法で、これは自分で内容を選びながら学ぶことが推奨されます。また、無料の動画サイトやYouTubeでPythonに関する教育動画を視聴する方法もあります。さらに、Progateやドットインストール、Udemyなどの有料の学習サイトを利用する方法も一般的です。それぞれの方法にはメリットとデメリットがあるため、個々の学習スタイルや目的に合わせて選択することが重要です。\"),\n",
    "]\n",
    "new_msg = contextualize_chain.invoke({\"chat_history\": messages, \"input\": \"1つ目について教えてください\"})\n",
    "print(new_msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-3. チャットの実装\n",
    " ここでは公式ドキュメントの方法ではなく、理解のしやすさとバージョン更新の影響を減らすために  \n",
    " Langchainの基本的な（変更が今後すくなさそうな）処理で実装しています"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_sample = [\n",
    "    \"LLMはどんな訓練方法がありますか？\",\n",
    "    \"2つ目についておしえてください\"\n",
    "]\n",
    "messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: LLMはどんな訓練方法がありますか？ >  LLM（大規模言語モデル）の訓練方法にはどのようなものがありますか？\n",
      "AI: LLM（大規模言語モデル）は、膨大なラベルなしテキストを使用して自己教師あり学習または半教師あり学習によって訓練が行われます。\n",
      "Human: 2つ目についておしえてください >  LLMの半教師あり学習について詳しく教えてください。\n",
      "AI: 半教師あり学習では、ラベル付きデータとラベルなしデータの両方を使用してモデルを訓練します。これにより、ラベル付きデータが少ない場合でも効果的に学習を進めることができます。\n"
     ]
    }
   ],
   "source": [
    "for msg in messages_sample:\n",
    "    # 質問を修正する\n",
    "    new_msg = contextualize_chain.invoke({\"chat_history\": messages, \"input\": msg})\n",
    "    print(\"Human:\", msg, \"> \", new_msg)\n",
    "    # 関連ドキュメントを取得\n",
    "    relavant_docs = retriever.invoke(new_msg, k=3)\n",
    "    # 質問に回答する\n",
    "    response = chain.invoke({\"chat_history\": messages, \"context\": relavant_docs, \"input\": msg})\n",
    "    print(\"AI:\", response.content)\n",
    "    # メッセージを保存\n",
    "    messages.extend([\n",
    "        HumanMessage(content=msg), # 作り直したほうではなく、ユーザー入力の方にする\n",
    "        AIMessage(content=response.content)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='LLMはどんな訓練方法がありますか？'),\n",
       " AIMessage(content='LLM（大規模言語モデル）は、膨大なラベルなしテキストを使用して自己教師あり学習または半教師あり学習によって訓練が行われます。'),\n",
       " HumanMessage(content='2つ目についておしえてください'),\n",
       " AIMessage(content='半教師あり学習では、ラベル付きデータとラベルなしデータの両方を使用してモデルを訓練します。これにより、ラベル付きデータが少ない場合でも効果的に学習を進めることができます。')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-5. チャットの実装 Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: LLMはどんな訓練方法がありますか？ >  LLMの訓練方法にはどのようなものがありますか？\n",
      "|LL|M|の|訓|練|方法|に|は|、|教|師|あり|学|習|、|自|己|教|師|あり|学|習|、|強|化|学|習|（|RL|HF|）、|カ|リ|キ|ュ|ラ|ム|学|習|な|ど|が|あり|ます|。|これ|ら|の|方法|を|通|じ|て|、|モ|デ|ル|は|膨|大|な|テ|キ|スト|デ|ータ|から|パ|タ|ー|ン|を|学|習|し|、|言|語|的|タ|ス|ク|を|実|行|する|能|力|を|身|に|つ|け|ます|。||/n\n",
      "Human: 2つ目についておしえてください >  自己教師あり学習とは、どのような訓練方法ですか？\n",
      "|自|己|教|師|あり|学|習|では|、|ラ|ベ|ル|付|き|デ|ータ|を|必|要|と|せ|ず|、|モ|デ|ル|自|身|が|生成|した|デ|ータ|を|使用|して|訓|練|を|行|います|。|例|え|ば|、|文|から|一|部|の|単|語|を|隠|し|、|モ|デ|ル|に|その|隠|され|た|単|語|を|予|測|さ|せ|る|こ|と|で|、|言|語|の|理|解|を|深|め|る|訓|練|が|行|わ|れ|ます|。|この|方法|は|大|量|の|未|ラ|ベ|ル|の|テ|キ|スト|デ|ータ|を|活|用|で|き|る|た|め|、|実|世|界|の|ア|プ|リ|ケ|ーシ|ョ|ン|に|適|して|います|。||/n\n"
     ]
    }
   ],
   "source": [
    "for msg in messages_sample:\n",
    "    # 質問を修正する\n",
    "    new_msg = contextualize_chain.invoke({\"chat_history\": messages, \"input\": msg})\n",
    "    print(\"Human:\", msg, \"> \", new_msg)\n",
    "    # 関連ドキュメントを取得\n",
    "    relavant_docs = retriever.invoke(new_msg, k=3)\n",
    "    # 質問に回答する Streaming\n",
    "    full_response = \"\"\n",
    "    for r in chain.stream({\"chat_history\": messages, \"context\": relavant_docs, \"input\": msg}):\n",
    "        full_response+=r.content\n",
    "        print(r.content, end=\"|\")    \n",
    "    print(\"/n\")\n",
    "    messages.extend([\n",
    "        HumanMessage(content=msg),\n",
    "        AIMessage(content=full_response)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
